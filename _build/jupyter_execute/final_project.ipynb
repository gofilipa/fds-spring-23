{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective: \n",
    "To explore & analyze how a language model from the\n",
    "*Transformers* libary generates text based on specific prompts. You\n",
    "will have the choice of analyzing discrimination and bias, or\n",
    "analyzing a topic of your choosing. If you choose to do the latter,\n",
    "you must also submit your prompts that you use for inputing to the\n",
    "language model.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "\n",
    "Steps: \n",
    "- First, you will load up a dataset for analysis. In the default\n",
    "  option, this dataset is \"[toxcicity\n",
    "  prompts](https://huggingface.co/datasets/allenai/real-toxicity-prompts),\"\n",
    "  which is a collection of prompts that tend to provoke biased\n",
    "  responses. You will load this dataset using the provided code in the\n",
    "  assignment sheet, which contains an if statement that filters out\n",
    "  the prompts by toxicity score. \n",
    "- Second, trom the dataset, you will compile a list of 20 prompts, using the\n",
    "  provided code in the assignment sheet. Later on, you will draw from\n",
    "  this list to feed prompts into the text generator. You may use the\n",
    "  code provided.\n",
    "- Third, you will create a generator object tied into which you will\n",
    "  pass your prompts. Here, you may use the default language model\n",
    "  (which is 'distil-gpt2', or use one of your choosing from the\n",
    "  [models\n",
    "  hub](https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads)),\n",
    "  with the \"text generation\" option from the \"Natural Language\n",
    "  Processing\" selected on the lefthand menu. If selecting your own\n",
    "  model, modify the code provided by adding a\n",
    "  ~model='your-model-name'~ argument in the pipeline function. \n",
    "- Fourth, pick out five prompts from your list of twenty to pass into\n",
    "  the generator object. You can create a slice (using list slicing) or\n",
    "  specify the index for each prompt, one at a time. Use the\n",
    "  code provided, but modify it to select the 5 prompts of your\n",
    "  choosing. \n",
    "- Fifth, when you've selected your prompts, pass them into the generator\n",
    "  object, which you created from the pipeline function.\n",
    "- Finally, examine the results and summarize your response. Pay\n",
    "  attention to anything that sticks out to you. Do you find the\n",
    "  results to be more biased or offensive than the original prompt? Do\n",
    "  you find them to be more biased or offensive than the \"continuation\"\n",
    "  sentences from the original dataset. Write up a summary of your\n",
    "  examination."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}