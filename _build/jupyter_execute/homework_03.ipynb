{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# homework 3: text cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please download this page by pressing the download button on upper right corner. You should save the page as an `.ipynb` file. \n",
    "\n",
    "Afer downloading the document, open it on your own computer, either on Google Colab or Jupyter-Notebooks. If using Google Colab, you may need to first upload the document to your Google Drive before you can work on it.\n",
    "\n",
    "When you are finished, download the document as an `.ipynb` file and submit it through Blackboard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading up the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, you will choose a text that you've read/seen before, ideally from the Project Gutenburg library: https://www.gutenberg.org/browse/scores/top. Make sure you select a the \"plain text\" link for the book. \n",
    "\n",
    "Then, in the cells below, you will load up your text into a Jupyter notebook or Google Colab notebook and follow the directions for each cell. FYI - you can find all of the code to fill out this section in the class notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the libraries we need to analyze text (nltk) and get \n",
    "# data over URLs (urllib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, grab the URL of your text from Gutenberg (or elsewhere) and \n",
    "# save it to a variable called \"my_url\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the URL address with urlopen(my_url) and save it to \"opened_url\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data in the URL using read() and save it to \"raw\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our data is currently in byte type, so we need to convert it to a \n",
    "# string type using decode(). Save the result to \"decoded\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will tokenize the text. Follow the directions in each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NLTK \"word_tokenize\" method to create a list of \"tokens,\"\n",
    "# or smaller strings, from our long string above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the first ten words from our list of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing punctuation and capital letters\n",
    "For this section, you will copy/paste the code fill in the missing lines (indicated with comments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and paste the below loop to the cell underneath this one. Then, complete the loop (at the commented line) to remove punctuation and capital leters.\n",
    "```python\n",
    "no_punct = []\n",
    "\n",
    "# write the first line of the for loop here\n",
    "  if word.isalpha():\n",
    "    no_punct.append(word.lower())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy and paste the above loop into this cell \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and paste the below loop to the cell underneath this one. Then, complete the loop (at the commented line) to remove stopwords.\n",
    "\n",
    "```python\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "o_unstopped = []\n",
    "for t in o_text:\n",
    "    if # complete the if statment here\n",
    "        o_unstopped.append(t)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy and paste the above loop into this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: \n",
    "Why do we want to go through the process of cleaning the text? Explain in 2-3 sentences in a comment below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}