{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# transformers: introduction"
      ],
      "metadata": {
        "id": "UM3DlhWOxRtN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUPUXIFWvGQu",
        "outputId": "813bdb7c-c9e4-4870-f2fc-1a888657c55b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ],
      "source": [
        "# first, install the library Transformers\n",
        "# you only need to install this library once. \n",
        "\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the transformers library, along with the pipeline and set_seed functions\n",
        "\n",
        "import transformers\n",
        "from transformers import pipeline, set_seed"
      ],
      "metadata": {
        "id": "c3MiVBYyxYNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## text generation\n",
        "generates new text based on an input prompt, like a chatbot. "
      ],
      "metadata": {
        "id": "LpGPdYD6xPsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pulling in the text generation \"pipeline\", and setting it to the variable\n",
        "# called \"generator\"\n",
        "\n",
        "generator = pipeline('text-generation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434,
          "referenced_widgets": [
            "e85c539cbf8641ccb1a44367bfd9dc99",
            "52a6ab8af74342f4ba5648c598c4954d",
            "8872363a5cdb45fe82d1b43465c168f3",
            "410068b364144f0bb48014bcd273bbea",
            "2a7684c194b04b95b8a272a7dcd67dc5",
            "046caf3d165142ba848d95b49ebadbc3",
            "d9c36ed8b042466da8e47fcdbc2da425",
            "0a17f4ed5069467d839397342c72af5f",
            "a74c78d08ba14387b6b7d6084514122d",
            "b53ee14200e3489bacf9df525b28dbfa",
            "57756ecc597d43e5a413bbb52e13a168",
            "3321802876894b7594cbd687f5aafe76",
            "c83fe15b40ef40029a2d74123f546648",
            "4d1f131e02f04be1bbdca5887a87528b",
            "8f557705452244699d4cb692ed8b8e16",
            "102d0e997e214211bf79af63978e4b17",
            "d47b54f38f864280ab1bb8ab52ba6706",
            "f4f111aa445b4e0698165a5924a66068",
            "5b6227804cdd4fb5b531765ce74ebf40",
            "a935245941b349b3aae3d630e020352d",
            "7621fe2462814668ab5f0722f9bf18fa",
            "c78f82c2658f48808b78b14aee381849",
            "3564ca44d3544ca089945d37b1b8f665",
            "9d4aecc830674bda909e5ca309d45ab1",
            "b63552d6f90b49e995412f64b7335039",
            "0a3a446472ac415db135c5cfb24227ac",
            "50f6218ea1b54e7aa2fcf46d51c5f59a",
            "6bb55b21256a450aa354b35cba30ba62",
            "b01ab7cbf4084c6991655fe66b75f549",
            "feb4b48c39384330bbff6977f0b25cb3",
            "ff2361ef3c0240d69ed6d58c469a9bbe",
            "011e33bf8e1243c588116e739e8e3d55",
            "5395885936234f3e8c85306f8b121a23",
            "710aaa70ad4f4f07bfb7470d2ddd8212",
            "b481619c612842b1872c16703c3694bc",
            "4c1d281a5b11417c8dfd688970289c4a",
            "d49155fe22f24d77bdb7d3f70ea5b1cc",
            "44763535f47c40d8849e11de49e9481f",
            "dd96f6860f8640e4859f9d52de7332ad",
            "6b32d4719a254bea8ea21e0d72463d02",
            "808be5eef1a14f4aa6cc7632e27e41f7",
            "bb70bbc0b1c74b1b8ab1f7822f3c3c74",
            "6ecc0e829ff440bb86bc2a6d6e350087",
            "e5b1cc8925964e57b7843a6fd581ed6f",
            "2eeea0eb6e274ccd89f2b3753947c9aa",
            "0dc9501df18e4bb0beae84119b7dd147",
            "4db3e39d59454e2fa18c3b417b416300",
            "b8fd6ad78d304bdda35325def6680ac7",
            "2e396cae908d4154a3656c379e5aa580",
            "b9f68aab89064916aa44c048e535bd46",
            "1959024c7d3f484e965ed24c6ac26719",
            "447c0b2dacb445619547b32c6a890a34",
            "4bfe95ab42a14ca7bd1e14db13e4da78",
            "80b10292304f4eb285992c4e9f8dcbcd",
            "e262c2029f7646be974b80645f97b730",
            "8815cbcdbd2c473c9a48edeb78cf4ff9",
            "bd976b0361dd43ed901593a68e47318c",
            "8d08c7608ae448579b204633e33d64d1",
            "ab46e0da3d284134944a4da8186c7543",
            "c537dcb6e5af49018ade4111a0cfc02c",
            "e078be3db0624b82b560d51b122668d5",
            "26c438850b7b499c80eb2c1cc21396c7",
            "e1dbf79ec9bf414795612a8f15c67f79",
            "67a521dce1974b71abebc2be56131c36",
            "1bc6c64e6f37465bb7c49f96106e1702",
            "5ef799cdbcad45c3abb8fc9498d3200c"
          ]
        },
        "id": "HCGKMhpIwgI6",
        "outputId": "d8d9996f-eb83-415d-bb16-b4dd6ec3a9af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e85c539cbf8641ccb1a44367bfd9dc99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3321802876894b7594cbd687f5aafe76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3564ca44d3544ca089945d37b1b8f665"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "710aaa70ad4f4f07bfb7470d2ddd8212"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2eeea0eb6e274ccd89f2b3753947c9aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8815cbcdbd2c473c9a48edeb78cf4ff9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# taking the generator function and passing a sentence and maximum length and \n",
        "# number of responses to the function\n",
        "\n",
        "generator('This summer, I was rock climbing in Yosemite when',\n",
        "          max_length=50,\n",
        "          num_return_sequences=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2Fssv7MyMCQ",
        "outputId": "3a7d9329-8990-4d1b-9de4-2e08068b7d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"This summer, I was rock climbing in Yosemite when I saw Yosemite Park and how we were both in different places. All of our friends from that group were in the park too. We all went up there together (we didn't even have clothes).\"},\n",
              " {'generated_text': 'This summer, I was rock climbing in Yosemite when I saw a very unusual looking figure wearing a hooded dress. The man went down there with a white hat and shorts while wearing a black dress. He had the same hair like a man, a'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fill mask\n",
        "Fills the word in the blank with a guess"
      ],
      "metadata": {
        "id": "cpebcd7flh9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the \"unmasker\" variable set to the \"fill-mask\" task\n",
        "\n",
        "unmasker = pipeline('fill-mask')"
      ],
      "metadata": {
        "id": "Rb-CFBvBy5xX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374,
          "referenced_widgets": [
            "efaaf43944fe4988a3267ee19c7da22e",
            "3c0036d8c6b5441481a5819bf9cfd381",
            "ab6ed4c61f0c4659afdb9e3c5a37d5d2",
            "ba07c13d545a4c93bac2774af0894ce7",
            "535145f3bcbb44da95f985762c556439",
            "58d5a17705d243289d64b3346a24a021",
            "68e1e13e2c414cbe92ae8b953fdc5f86",
            "c998b1f4793f41be88ce836c3cce03b9",
            "bf64343185a342dab5e713c74711d3ab",
            "fa3dfe83f06d4d7b9fc4389d78da33e6",
            "d45a8386d36b48b588e3899dbaf3d881",
            "e9557587ee3c449ca771d4a3941e3f41",
            "e52cacc1a38f4de1931212cb5d53dea0",
            "a0b1afb4bb1c426ea2a1ce41e8ec3784",
            "020eabf924b94a69a45173f26fa04b30",
            "ac9ce2ae9578455786c2483c4a3d7eb5",
            "b768a517ff044d69b8ea4f57c7f3cc17",
            "2e93ab55b56a493a830d0aa6b27c8e63",
            "b3a9740116fb4e39bb3460d899a82761",
            "46faa76bb3694472a4e8837616392b1f",
            "cdadfee5bdf94b48b0e8470aed76bf60",
            "2504f5851cb748f69263eed129bc76b1",
            "0dad6820d47744e6a4bf5a39fc6c433a",
            "4d40a7741c4a4e32b32097d51b65fc03",
            "0b9ff79e88f84d1fa915d5c82ae84598",
            "e5de1fea2b1a456ca058ed87df53365d",
            "6306e4116d784b7dad6bdbeb1418c7b5",
            "324997d14a954b109a2acaf9f8c807ab",
            "b171e13e5abb4430bbbbb00d61868c5e",
            "fc9348493572474b95caf05b2ea7a96d",
            "b140c8b71bd1416091034318915eb823",
            "027bf2d9a8c746ddbb9b2536e28f0784",
            "390a6d0af1ab4b28adafe0a07327105b",
            "4c581e6b4b494b9eaf0a0cf5401e8871",
            "1806c084382441a7bdbfedc8b2f530f3",
            "c8c2b46407c4489d94fb9c88a89e8a0f",
            "a006ac25c9454e79ada23161a8d3ef12",
            "667cc5b75eb143fe8cafa6bb182d2119",
            "a5ff438c4bf14ddbb96854d03b6b3fc6",
            "727fd9f90c94423bb70a9406ad013ed4",
            "bce7d8bed6e04f6c929e2d104b6e4a4c",
            "e902ac3b45574c15b76fb04d9f781bee",
            "d5f2353670404156b40e1eda9c639806",
            "2138a20bc1a84fc0929de5268ae04acc",
            "09f6f3d49e97497bb400d5811ddec7f9",
            "f0e8ce1c7f164544a2c82f41584ae6ac",
            "7f44d75d657e43f0b9ea4e5af3e70dfa",
            "bd3cacfda33c42d49e8881210d4cde67",
            "21762f60cd7d43f485ac0e703a9243f0",
            "f927d1723cc1460cb90c81975befff90",
            "17cf6e30942a4583853692ca114b694f",
            "ccb6c9d39a3a49a9b0c53d3e0792a272",
            "833a501542e74784903e186cbf63ef9c",
            "790c0346e83b4802ada2079768b2bc19",
            "fc142a69f62f4c5fb1792f7db85c45da"
          ]
        },
        "outputId": "383a7677-fb27-4988-f2e8-fd9139ceea81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efaaf43944fe4988a3267ee19c7da22e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/331M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9557587ee3c449ca771d4a3941e3f41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dad6820d47744e6a4bf5a39fc6c433a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c581e6b4b494b9eaf0a0cf5401e8871"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09f6f3d49e97497bb400d5811ddec7f9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# give it a sentence, with the <mask> as a fill in the blank\n",
        "# the \"top_k\" argument means we will get 4 responses\n",
        "\n",
        "unmasker('To be or not to be; that is the <mask>', top_k=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpVu1A74lqia",
        "outputId": "b690f35d-e924-4b2b-9d29-60a1bd79e6f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.10899456590414047,\n",
              "  'token': 2249,\n",
              "  'token_str': ' difference',\n",
              "  'sequence': 'To be or not to be; that is the difference'},\n",
              " {'score': 0.057923685759305954,\n",
              "  'token': 2031,\n",
              "  'token_str': ' choice',\n",
              "  'sequence': 'To be or not to be; that is the choice'},\n",
              " {'score': 0.0572822242975235,\n",
              "  'token': 3157,\n",
              "  'token_str': ' truth',\n",
              "  'sequence': 'To be or not to be; that is the truth'},\n",
              " {'score': 0.04440426453948021,\n",
              "  'token': 1948,\n",
              "  'token_str': ' answer',\n",
              "  'sequence': 'To be or not to be; that is the answer'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker('My name is Professor Calado and I teach at <mask>', top_k=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhoMyHw-mYWV",
        "outputId": "275954a6-87cf-4902-f314-4a94c23b0aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.1351284384727478,\n",
              "  'token': 20124,\n",
              "  'token_str': ' MIT',\n",
              "  'sequence': 'My name is Professor Calado and I teach at MIT'},\n",
              " {'score': 0.07084151357412338,\n",
              "  'token': 10441,\n",
              "  'token_str': ' UCLA',\n",
              "  'sequence': 'My name is Professor Calado and I teach at UCLA'},\n",
              " {'score': 0.06717374920845032,\n",
              "  'token': 8607,\n",
              "  'token_str': ' Stanford',\n",
              "  'sequence': 'My name is Professor Calado and I teach at Stanford'},\n",
              " {'score': 0.06465509533882141,\n",
              "  'token': 23706,\n",
              "  'token_str': ' BYU',\n",
              "  'sequence': 'My name is Professor Calado and I teach at BYU'}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## summarization\n",
        "Takes a longer text and condenses it."
      ],
      "metadata": {
        "id": "oKsE7gyFqB_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# taking the \"summarization\" task and saving it to \"summarizer\"\n",
        "# then passing some text into the \"summarizer\"\n",
        "\n",
        "# we use three quotes at the beginning and end of the string \n",
        "# if we want to put in a text that spans multiple lines\n",
        "\n",
        "summarizer = pipeline('summarization')\n",
        "summarizer('''The past 3 years of work in NLP have been characterized \n",
        "by the development and deployment of ever larger language models, \n",
        "especially for English. BERT, its variants, GPT-2/3, and others, \n",
        "most recently Switch-C, have pushed the boundaries of the possible \n",
        "both through architectural innovations and through sheer size. Using \n",
        "these pretrained models and the methodology of fine-tuning them for \n",
        "specific tasks, researchers have extended the state of the art on a \n",
        "wide array of tasks as measured by leaderboards on specific benchmarks \n",
        "for English. In this paper, we take a step back and ask: How big is too \n",
        "big? What are the possible risks associated with this technology and \n",
        "what paths are available for mitigating those risks? We provide \n",
        "recommendations including weighing the environmental and financial costs \n",
        "first, investing resources into curating and carefully documenting \n",
        "datasets rather than ingesting everything on the web, carrying out \n",
        "pre-development exercises evaluating how the planned approach fits into \n",
        "research and development goals and supports stakeholder values, and \n",
        "encouraging research directions beyond ever larger language models.''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466,
          "referenced_widgets": [
            "eeea02abc85247dbb0d1fd6aec9bf9c6",
            "6f250da5e26a40e299d4d0d1a9ad8c34",
            "3a4b05c62bb645ddaf597d354114a1e9",
            "edc9215d712547d293c44929369b644b",
            "878f7aa4848843b5be3fda8a4b91776f",
            "537438a0daac45ea9b5d57994068c021",
            "e187bb67df8c44f79344b105c445bfa1",
            "a003e344d64044e1993e5cec6c3e1ffc",
            "18cd9df6f32d44368f1700401ccd8089",
            "b211fbbec4e440799211a1c4c64bca23",
            "6fa02f90bc8f4c1ca36241958bd1fccd",
            "41d0f7423d6445c7b593de3703b37d3d",
            "452ba1095cfe41128f3471079beafe8f",
            "b92afca3c00544358cb873faa26f579f",
            "5162db0f0e194e5793de3f2b31ea14e6",
            "1327af40cf674a14aaf9683830e5c383",
            "f978186b3e42401d93ca65e1de97e551",
            "5977c3740c4846ae99d293c4954501cd",
            "8c98c70e51a744e09ce280de072ee73d",
            "82dedfa2d61f434da8efa1694d0f8e9a",
            "449766c26526457ba3c801ce34c4b8c3",
            "efa3689ead17401d84ff6275cf87d5ca",
            "86be71dd98264079b8dbd70d28e5db1d",
            "310ee11a5625438883f5c9dc0af0ca85",
            "f7d876d44aa841e2a2af614d5ac5dedb",
            "3f330e09502f402480bb29d990699dcd",
            "2945733e9e834d4880da8aea37881a73",
            "8335292d31cb4d7b8cf1880dfaf001e2",
            "29886b5a4adb49b39b8d3fd9c122cf74",
            "a2f482bc3da34ce0879e088066b2cd29",
            "53830e4c13d24597946dcc736d92ec4b",
            "df985f49fec543e89fb862d5b5a77f9b",
            "ffc29fc3a52b43e190b0ba863719b9f5",
            "8f0bf6f8647b43ae8e8da8165b14a403",
            "4f160b36039644209f250f338f916415",
            "9321c67e2cb143f9a657faae2f72c78e",
            "72bbb181b09646e0961543e40a7fafd3",
            "0bfb73f2d13048b0b5e018ed8b8d49c8",
            "aeba5864696c486183ee030b880c0e6f",
            "df4b882286134486ac9c254631d80d10",
            "27f5a5781ef248558258f633328d0326",
            "54f16551dcb3468dac18aebec9638efd",
            "ba5f26a2512141b68c1d4c0d987bbaf0",
            "33ea25d1b70d497499cc33ffc0738e81",
            "c8028fc6d2db49a68e4f733126afa175",
            "88935481c25a495aafefdc3e22794ea2",
            "776bc43a4ec24bd7b9018044a826f3f8",
            "231f57034a5a4465a4944950417a42c7",
            "38dd19dc92284b8d9e6cdd88a08975f2",
            "ed0fdaa451714c86ac560caa28beffb7",
            "fe3b67fe7e9e493c9ab1cd27c5f4a0d4",
            "839dbf2f0b174514b41f477d47ffc5eb",
            "280cd853723a40cd855c1a84301d7055",
            "a2323fa40dcc40b09194bf17a2bfb0eb",
            "1d680a2a66ed48f08dc4c5dc56e8a66c"
          ]
        },
        "id": "eSNrJUFBmzmR",
        "outputId": "6e1f8f52-c3e1-4899-94e1-108ae97c18f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eeea02abc85247dbb0d1fd6aec9bf9c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41d0f7423d6445c7b593de3703b37d3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86be71dd98264079b8dbd70d28e5db1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f0bf6f8647b43ae8e8da8165b14a403"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8028fc6d2db49a68e4f733126afa175"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models,  especially for English . In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks?'}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## question-answering\n",
        "Takes an input question and context and provides an answer"
      ],
      "metadata": {
        "id": "GYwbSsN7rMUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calling the question-answer pipeline\n",
        "# passing a question and context into the pipeline\n",
        "# the function will look into the context to get the answer\n",
        "\n",
        "question_answer = pipeline('question-answering')\n",
        "question_answer(question='Was the writer of Frankenstien a man or a woman?', \n",
        "                context='''Frankenstien is a book written by Mary Shelley who is \n",
        "                a woman''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxpi8p31qx76",
        "outputId": "685a048d-153d-4fcd-f373-a49ee2a86a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.6520994901657104, 'start': 71, 'end': 78, 'answer': 'a woman'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ner (named entity recognition)\n",
        "Named entity recognition (NER) is a task where the model has to find which parts of the input text correspond to entities such as persons, locations, or organizations."
      ],
      "metadata": {
        "id": "Eu4_q9uMrbVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"My name is Filipa Calado and I work at City College in Manhattan.\")"
      ],
      "metadata": {
        "id": "yC0oHzufrjc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521,
          "referenced_widgets": [
            "e6d2e774a63c459f9f53b35227bac4dc",
            "02f11a5c1ed5479e9cddee7e3519a913",
            "0ddbfb9544404d448e7655ced70a1899",
            "049a3534f55d45fbb64628178527f77a",
            "a8fdfc51d2e940519b7a4ff2f07353e7",
            "b8540eee926649fa9ceff8ec76251690",
            "e11c0aa83bd74553a1ca8d4ea5440294",
            "f7eaea116a6d416f95785ae87096f64c",
            "add61703843d40a4b102e39b61b4752b",
            "6c7fff08223545f9af34893ff43f2976",
            "0b40d06c49874f9587d581ba471c1d69",
            "22a0dceb96994afabd0c44c4968ba1cd",
            "106acf21ad4a4af08abdf6a10091e8b9",
            "93a81c580db64524bc186f847d62b929",
            "bcc7429b73004255bd9e11e0c7cde04e",
            "d40f662e6ad2464384cbb3498ce0fe8a",
            "15fff51537c541a6bd7942f1660263ed",
            "8dd1a81954e94071af7433bc0a90c17a",
            "554cfc3093a648feaca99171e6712478",
            "e90172efc5cf40ce96eec642a5273a40",
            "0e7e79d983cf4a06ae928fb4f542a753",
            "219ac95052aa4923bd5ab6eefa7bc5f6",
            "a6e3c1f389824e41bb0063e3c6f0015a",
            "572d7f7239e84845bcaba1112cd70adb",
            "1aedc3265a6a47a5b9e44c2907016505",
            "1a58262c4e5e41808d7d111399075c56",
            "b2e181fb73854ea6bc234b3da7eedc85",
            "59325570be7c4d41bfc0a3bee60e835e",
            "5d4df5ed6f4240afb178a80af2e37086",
            "507a33786b8b49ad982bbe7178074495",
            "95da5a358ca64aeaa086e615c0788bb7",
            "691b2251bdc54ad5bc42a5d111db7348",
            "f988f7bb185b4bf3aae8e264c701ccf6",
            "4133165a1f9d47f0b2d146cabe9ee98e",
            "6ca84b27029443f286f5c1bfc66245aa",
            "30ec6428f31b45caba999f7e4b3a98cf",
            "3f919545ef474d1f8fb945e2a68bb435",
            "6357ddc898444f35910f12d4650d26c9",
            "ef9e3a1fa0dc4b42a5050d09a7d12722",
            "583f501abeec416984ae5d3b5919dfae",
            "66b054e01e894f858581de68570eb854",
            "945d65f3a94a48c5a7bbc108ea5bf8aa",
            "561f3732e4ce4205a1699eab5b2e8a93",
            "96bfd99ee1694e1c858e2690825284f2"
          ]
        },
        "outputId": "31f3a0a3-6f6c-4c48-97c9-e12a7a3bc618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6d2e774a63c459f9f53b35227bac4dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22a0dceb96994afabd0c44c4968ba1cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6e3c1f389824e41bb0063e3c6f0015a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4133165a1f9d47f0b2d146cabe9ee98e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/pipelines/token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.9985998,\n",
              "  'word': 'Filipa Calado',\n",
              "  'start': 11,\n",
              "  'end': 24},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.9940423,\n",
              "  'word': 'City College',\n",
              "  'start': 39,\n",
              "  'end': 51},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9883624,\n",
              "  'word': 'Manhattan',\n",
              "  'start': 55,\n",
              "  'end': 64}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "koGYMQa99mki"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}