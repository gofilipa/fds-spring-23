

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>transformers: introduction &#8212; Foundations of Data Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'intro_transformers';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="transformers: generating language" href="generating_language.html" />
    <link rel="prev" title="NLTK: text analysis" href="nltk-gender.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="syllabus.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="syllabus.html">
                    Syllabus
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="schedule.html">Course Schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_types_variables.html">Data Types and Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="functions.html">Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="loops_and_lists.html">Loops and Lists</a></li>
<li class="toctree-l1"><a class="reference internal" href="nltk-intro.html">NLTK: nltk.book</a></li>
<li class="toctree-l1"><a class="reference internal" href="nltk_cleaning.html">NLTK: cleaning part one</a></li>



<li class="toctree-l1"><a class="reference internal" href="nltk-cleaning-2.html">NLTK: cleaning part two</a></li>
<li class="toctree-l1"><a class="reference internal" href="nltk-gender.html">NLTK: text analysis</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">transformers: introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="generating_language.html">transformers: generating language</a></li>
<li class="toctree-l1"><a class="reference internal" href="transformers_bias.html">transformers: bias &amp; discrimination</a></li>
<li class="toctree-l1"><a class="reference internal" href="homework_00.html">homework 0: install python (optional)</a></li>
<li class="toctree-l1"><a class="reference internal" href="homework_01.html">homework 1: data types and variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="homework_02.html">homework 2: python basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="homework_03.html">homework 3: text cleaning</a></li>
<li class="toctree-l1"><a class="reference internal" href="homework_04.html">homework 4: text analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="final_project.html">Final Project</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/intro_transformers.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>transformers: introduction</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-generation">text generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fill-mask">fill mask</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summarization">summarization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#question-answering">question-answering</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ner-named-entity-recognition">ner (named entity recognition)</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="transformers-introduction">
<h1>transformers: introduction<a class="headerlink" href="#transformers-introduction" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># first, install the library Transformers</span>
<span class="c1"># you only need to install this library once. </span>

<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>transformers
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: transformers in /Users/caladof/anaconda3/lib/python3.11/site-packages (4.29.2)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: filelock in /Users/caladof/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.14.1 in /Users/caladof/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.1)
Requirement already satisfied: numpy&gt;=1.17 in /Users/caladof/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)
Requirement already satisfied: packaging&gt;=20.0 in /Users/caladof/anaconda3/lib/python3.11/site-packages (from transformers) (23.0)
Requirement already satisfied: pyyaml&gt;=5.1 in /Users/caladof/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)
Requirement already satisfied: regex!=2019.12.17 in /Users/caladof/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)
Requirement already satisfied: requests in /Users/caladof/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)
Requirement already satisfied: tokenizers!=0.11.3,&lt;0.14,&gt;=0.11.1 in /Users/caladof/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.2)
Requirement already satisfied: tqdm&gt;=4.27 in /Users/caladof/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)
Requirement already satisfied: fsspec in /Users/caladof/anaconda3/lib/python3.11/site-packages (from huggingface-hub&lt;1.0,&gt;=0.14.1-&gt;transformers) (2023.4.0)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /Users/caladof/anaconda3/lib/python3.11/site-packages (from huggingface-hub&lt;1.0,&gt;=0.14.1-&gt;transformers) (4.7.1)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /Users/caladof/anaconda3/lib/python3.11/site-packages (from requests-&gt;transformers) (2.0.4)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: idna&lt;4,&gt;=2.5 in /Users/caladof/anaconda3/lib/python3.11/site-packages (from requests-&gt;transformers) (3.4)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /Users/caladof/anaconda3/lib/python3.11/site-packages (from requests-&gt;transformers) (1.26.16)
Requirement already satisfied: certifi&gt;=2017.4.17 in /Users/caladof/anaconda3/lib/python3.11/site-packages (from requests-&gt;transformers) (2023.7.22)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import the transformers library, along with the pipeline and set_seed functions</span>

<span class="kn">import</span> <span class="nn">transformers</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">set_seed</span>
</pre></div>
</div>
</div>
</div>
<section id="text-generation">
<h2>text generation<a class="headerlink" href="#text-generation" title="Permalink to this heading">#</a></h2>
<p>generates new text based on an input prompt, like a chatbot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># pulling in the text generation &quot;pipeline&quot;, and setting it to the variable</span>
<span class="c1"># called &quot;generator&quot;</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;text-generation&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).
Using a pipeline without specifying a model name and revision in production is not recommended.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers
pip install xformers.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># taking the generator function and passing a sentence and maximum length and </span>
<span class="c1"># number of responses to the function</span>

<span class="n">generator</span><span class="p">(</span><span class="s1">&#39;This summer, I was rock climbing in Yosemite when&#39;</span><span class="p">,</span>
          <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
          <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[{&#39;generated_text&#39;: &#39;This summer, I was rock climbing in Yosemite when I heard the first of six live moose, one of many of the first live booms with my mom. For weeks as we worked to clean up after the booms, we walked around the&#39;},
 {&#39;generated_text&#39;: &quot;This summer, I was rock climbing in Yosemite when a group of volunteers showed up to see me. I wasn&#39;t on the route, but I had been working hard and had a good time.\n\nI got a photo of my buddy Jesse,&quot;}]
</pre></div>
</div>
</div>
</div>
</section>
<section id="fill-mask">
<h2>fill mask<a class="headerlink" href="#fill-mask" title="Permalink to this heading">#</a></h2>
<p>Fills the word in the blank with a guess</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create the &quot;unmasker&quot; variable set to the &quot;fill-mask&quot; task</span>

<span class="n">unmasker</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;fill-mask&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).
Using a pipeline without specifying a model name and revision in production is not recommended.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "e2e2951824db481fa418475a801a4746"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "4185cd12678e41c09f98ecf182a236e6"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "0bc9299257f2459a8ff2ee4755ad372a"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "e940c74f6022404c916298079902dfd6"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "2d0244792afb420db00aeb3beadc1d9f"}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># give it a sentence, with the &lt;mask&gt; as a fill in the blank</span>
<span class="c1"># the &quot;top_k&quot; argument means we will get 4 responses</span>

<span class="n">unmasker</span><span class="p">(</span><span class="s1">&#39;To be or not to be; that is the &lt;mask&gt;&#39;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[{&#39;score&#39;: 0.10899507254362106,
  &#39;token&#39;: 2249,
  &#39;token_str&#39;: &#39; difference&#39;,
  &#39;sequence&#39;: &#39;To be or not to be; that is the difference&#39;},
 {&#39;score&#39;: 0.057924505323171616,
  &#39;token&#39;: 2031,
  &#39;token_str&#39;: &#39; choice&#39;,
  &#39;sequence&#39;: &#39;To be or not to be; that is the choice&#39;},
 {&#39;score&#39;: 0.05728177726268768,
  &#39;token&#39;: 3157,
  &#39;token_str&#39;: &#39; truth&#39;,
  &#39;sequence&#39;: &#39;To be or not to be; that is the truth&#39;},
 {&#39;score&#39;: 0.04440455138683319,
  &#39;token&#39;: 1948,
  &#39;token_str&#39;: &#39; answer&#39;,
  &#39;sequence&#39;: &#39;To be or not to be; that is the answer&#39;}]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">unmasker</span><span class="p">(</span><span class="s1">&#39;My name is Professor Calado and I teach at &lt;mask&gt;&#39;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[{&#39;score&#39;: 0.13512930274009705,
  &#39;token&#39;: 20124,
  &#39;token_str&#39;: &#39; MIT&#39;,
  &#39;sequence&#39;: &#39;My name is Professor Calado and I teach at MIT&#39;},
 {&#39;score&#39;: 0.07084149122238159,
  &#39;token&#39;: 10441,
  &#39;token_str&#39;: &#39; UCLA&#39;,
  &#39;sequence&#39;: &#39;My name is Professor Calado and I teach at UCLA&#39;},
 {&#39;score&#39;: 0.06717373430728912,
  &#39;token&#39;: 8607,
  &#39;token_str&#39;: &#39; Stanford&#39;,
  &#39;sequence&#39;: &#39;My name is Professor Calado and I teach at Stanford&#39;},
 {&#39;score&#39;: 0.06465483456850052,
  &#39;token&#39;: 23706,
  &#39;token_str&#39;: &#39; BYU&#39;,
  &#39;sequence&#39;: &#39;My name is Professor Calado and I teach at BYU&#39;}]
</pre></div>
</div>
</div>
</div>
</section>
<section id="summarization">
<h2>summarization<a class="headerlink" href="#summarization" title="Permalink to this heading">#</a></h2>
<p>Takes a longer text and condenses it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># taking the &quot;summarization&quot; task and saving it to &quot;summarizer&quot;</span>
<span class="c1"># then passing some text into the &quot;summarizer&quot;</span>

<span class="c1"># we use three quotes at the beginning and end of the string </span>
<span class="c1"># if we want to put in a text that spans multiple lines</span>

<span class="n">summarizer</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;summarization&#39;</span><span class="p">)</span>
<span class="n">summarizer</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;The past 3 years of work in NLP have been characterized </span>
<span class="s1">by the development and deployment of ever larger language models, </span>
<span class="s1">especially for English. BERT, its variants, GPT-2/3, and others, </span>
<span class="s1">most recently Switch-C, have pushed the boundaries of the possible </span>
<span class="s1">both through architectural innovations and through sheer size. Using </span>
<span class="s1">these pretrained models and the methodology of fine-tuning them for </span>
<span class="s1">specific tasks, researchers have extended the state of the art on a </span>
<span class="s1">wide array of tasks as measured by leaderboards on specific benchmarks </span>
<span class="s1">for English. In this paper, we take a step back and ask: How big is too </span>
<span class="s1">big? What are the possible risks associated with this technology and </span>
<span class="s1">what paths are available for mitigating those risks? We provide </span>
<span class="s1">recommendations including weighing the environmental and financial costs </span>
<span class="s1">first, investing resources into curating and carefully documenting </span>
<span class="s1">datasets rather than ingesting everything on the web, carrying out </span>
<span class="s1">pre-development exercises evaluating how the planned approach fits into </span>
<span class="s1">research and development goals and supports stakeholder values, and </span>
<span class="s1">encouraging research directions beyond ever larger language models.&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).
Using a pipeline without specifying a model name and revision in production is not recommended.
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "f5523bd9c9bc47f38cc9b331da93a69f"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "e3658063785d49efb4015e23ffda11f7"}</script><div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">line</span> <span class="mi">7</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># taking the &quot;summarization&quot; task and saving it to &quot;summarizer&quot;</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="c1"># then passing some text into the &quot;summarizer&quot;</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> 
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="c1"># we use three quotes at the beginning and end of the string </span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="c1"># if we want to put in a text that spans multiple lines</span>
<span class="ne">----&gt; </span><span class="mi">7</span> <span class="n">summarizer</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;summarization&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="n">summarizer</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;The past 3 years of work in NLP have been characterized </span>
<span class="g g-Whitespace">      </span><span class="mi">9</span><span class="s1"> by the development and deployment of ever larger language models, </span>
<span class="g g-Whitespace">     </span><span class="mi">10</span><span class="s1"> especially for English. BERT, its variants, GPT-2/3, and others, </span>
<span class="s1">   (...)</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span><span class="s1"> research and development goals and supports stakeholder values, and </span>
<span class="g g-Whitespace">     </span><span class="mi">24</span><span class="s1"> encouraging research directions beyond ever larger language models.&#39;&#39;&#39;</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/lib/python3.11/site-packages/transformers/pipelines/__init__.py:788,</span> in <span class="ni">pipeline</span><span class="nt">(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">784</span> <span class="c1"># Infer the framework from the model</span>
<span class="g g-Whitespace">    </span><span class="mi">785</span> <span class="c1"># Forced if framework already defined, inferred if it&#39;s None</span>
<span class="g g-Whitespace">    </span><span class="mi">786</span> <span class="c1"># Will load the correct model if possible</span>
<span class="g g-Whitespace">    </span><span class="mi">787</span> <span class="n">model_classes</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="n">targeted_task</span><span class="p">[</span><span class="s2">&quot;tf&quot;</span><span class="p">],</span> <span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="n">targeted_task</span><span class="p">[</span><span class="s2">&quot;pt&quot;</span><span class="p">]}</span>
<span class="ne">--&gt; </span><span class="mi">788</span> <span class="n">framework</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">infer_framework_load_model</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">789</span>     <span class="n">model</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">790</span>     <span class="n">model_classes</span><span class="o">=</span><span class="n">model_classes</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">791</span>     <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">792</span>     <span class="n">framework</span><span class="o">=</span><span class="n">framework</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">793</span>     <span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">794</span>     <span class="o">**</span><span class="n">hub_kwargs</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">795</span>     <span class="o">**</span><span class="n">model_kwargs</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">796</span> <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">798</span> <span class="n">model_config</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span>
<span class="g g-Whitespace">    </span><span class="mi">799</span> <span class="n">hub_kwargs</span><span class="p">[</span><span class="s2">&quot;_commit_hash&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">_commit_hash</span>

<span class="nn">File ~/anaconda3/lib/python3.11/site-packages/transformers/pipelines/base.py:270,</span> in <span class="ni">infer_framework_load_model</span><span class="nt">(model, config, model_classes, task, framework, **model_kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">264</span>     <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">265</span>         <span class="s2">&quot;Model might be a PyTorch model (ending with `.bin`) but PyTorch is not available. &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">266</span>         <span class="s2">&quot;Trying to load the model with Tensorflow.&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">267</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">269</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">270</span>     <span class="n">model</span> <span class="o">=</span> <span class="n">model_class</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">271</span>     <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;eval&quot;</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">272</span>         <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="nn">File ~/anaconda3/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:467,</span> in <span class="ni">_BaseAutoModelClass.from_pretrained</span><span class="nt">(cls, pretrained_model_name_or_path, *model_args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">465</span> <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">config</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_model_mapping</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
<span class="g g-Whitespace">    </span><span class="mi">466</span>     <span class="n">model_class</span> <span class="o">=</span> <span class="n">_get_model_class</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_model_mapping</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">467</span>     <span class="k">return</span> <span class="n">model_class</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">468</span>         <span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="o">*</span><span class="n">model_args</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="o">**</span><span class="n">hub_kwargs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="g g-Whitespace">    </span><span class="mi">469</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">470</span> <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">471</span>     <span class="sa">f</span><span class="s2">&quot;Unrecognized configuration class </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="vm">__class__</span><span class="si">}</span><span class="s2"> for this kind of AutoModel: </span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">472</span>     <span class="sa">f</span><span class="s2">&quot;Model type should be one of </span><span class="si">{</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="vm">__name__</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">cls</span><span class="o">.</span><span class="n">_model_mapping</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">.&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">473</span> <span class="p">)</span>

<span class="nn">File ~/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:2432,</span> in <span class="ni">PreTrainedModel.from_pretrained</span><span class="nt">(cls, pretrained_model_name_or_path, *model_args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">2417</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">2418</span>     <span class="c1"># Load from URL or cache if already cached</span>
<span class="g g-Whitespace">   </span><span class="mi">2419</span>     <span class="n">cached_file_kwargs</span> <span class="o">=</span> <span class="p">{</span>
<span class="g g-Whitespace">   </span><span class="mi">2420</span>         <span class="s2">&quot;cache_dir&quot;</span><span class="p">:</span> <span class="n">cache_dir</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">2421</span>         <span class="s2">&quot;force_download&quot;</span><span class="p">:</span> <span class="n">force_download</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2430</span>         <span class="s2">&quot;_commit_hash&quot;</span><span class="p">:</span> <span class="n">commit_hash</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">2431</span>     <span class="p">}</span>
<span class="ne">-&gt; </span><span class="mi">2432</span>     <span class="n">resolved_archive_file</span> <span class="o">=</span> <span class="n">cached_file</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="o">**</span><span class="n">cached_file_kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2434</span>     <span class="c1"># Since we set _raise_exceptions_for_missing_entries=False, we don&#39;t get an exception but a None</span>
<span class="g g-Whitespace">   </span><span class="mi">2435</span>     <span class="c1"># result when internet is up, the repo and revision exist, but the file does not.</span>
<span class="g g-Whitespace">   </span><span class="mi">2436</span>     <span class="k">if</span> <span class="n">resolved_archive_file</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">filename</span> <span class="o">==</span> <span class="n">_add_variant</span><span class="p">(</span><span class="n">SAFE_WEIGHTS_NAME</span><span class="p">,</span> <span class="n">variant</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">2437</span>         <span class="c1"># Maybe the checkpoint is sharded, we try to grab the index name in this case.</span>

<span class="nn">File ~/anaconda3/lib/python3.11/site-packages/transformers/utils/hub.py:417,</span> in <span class="ni">cached_file</span><span class="nt">(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)</span>
<span class="g g-Whitespace">    </span><span class="mi">414</span> <span class="n">user_agent</span> <span class="o">=</span> <span class="n">http_user_agent</span><span class="p">(</span><span class="n">user_agent</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">415</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">416</span>     <span class="c1"># Load from URL or cache if already cached</span>
<span class="ne">--&gt; </span><span class="mi">417</span>     <span class="n">resolved_file</span> <span class="o">=</span> <span class="n">hf_hub_download</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">418</span>         <span class="n">path_or_repo_id</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">419</span>         <span class="n">filename</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">420</span>         <span class="n">subfolder</span><span class="o">=</span><span class="kc">None</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">subfolder</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">subfolder</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">421</span>         <span class="n">repo_type</span><span class="o">=</span><span class="n">repo_type</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">422</span>         <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">423</span>         <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">424</span>         <span class="n">user_agent</span><span class="o">=</span><span class="n">user_agent</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">425</span>         <span class="n">force_download</span><span class="o">=</span><span class="n">force_download</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">426</span>         <span class="n">proxies</span><span class="o">=</span><span class="n">proxies</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">427</span>         <span class="n">resume_download</span><span class="o">=</span><span class="n">resume_download</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">428</span>         <span class="n">use_auth_token</span><span class="o">=</span><span class="n">use_auth_token</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">429</span>         <span class="n">local_files_only</span><span class="o">=</span><span class="n">local_files_only</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">430</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">432</span> <span class="k">except</span> <span class="n">RepositoryNotFoundError</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">433</span>     <span class="k">raise</span> <span class="ne">EnvironmentError</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">434</span>         <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">path_or_repo_id</span><span class="si">}</span><span class="s2"> is not a local folder and is not a valid model identifier &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">435</span>         <span class="s2">&quot;listed on &#39;https://huggingface.co/models&#39;</span><span class="se">\n</span><span class="s2">If this is a private repository, make sure to &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">436</span>         <span class="s2">&quot;pass a token having permission to this repo with `use_auth_token` or log in with &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">437</span>         <span class="s2">&quot;`huggingface-cli login` and pass `use_auth_token=True`.&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">438</span>     <span class="p">)</span>

<span class="nn">File ~/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118,</span> in <span class="ni">validate_hf_hub_args.&lt;locals&gt;._inner_fn</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">115</span> <span class="k">if</span> <span class="n">check_use_auth_token</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">116</span>     <span class="n">kwargs</span> <span class="o">=</span> <span class="n">smoothly_deprecate_use_auth_token</span><span class="p">(</span><span class="n">fn_name</span><span class="o">=</span><span class="n">fn</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">has_token</span><span class="o">=</span><span class="n">has_token</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">118</span> <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1364,</span> in <span class="ni">hf_hub_download</span><span class="nt">(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)</span>
<span class="g g-Whitespace">   </span><span class="mi">1361</span> <span class="k">with</span> <span class="n">temp_file_manager</span><span class="p">()</span> <span class="k">as</span> <span class="n">temp_file</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1362</span>     <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;downloading </span><span class="si">%s</span><span class="s2"> to </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">temp_file</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1364</span>     <span class="n">http_get</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1365</span>         <span class="n">url_to_download</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1366</span>         <span class="n">temp_file</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1367</span>         <span class="n">proxies</span><span class="o">=</span><span class="n">proxies</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1368</span>         <span class="n">resume_size</span><span class="o">=</span><span class="n">resume_size</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1369</span>         <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1370</span>         <span class="n">expected_size</span><span class="o">=</span><span class="n">expected_size</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1371</span>     <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1373</span> <span class="k">if</span> <span class="n">local_dir</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1374</span>     <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Storing </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2"> in cache at </span><span class="si">{</span><span class="n">blob_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:544,</span> in <span class="ni">http_get</span><span class="nt">(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)</span>
<span class="g g-Whitespace">    </span><span class="mi">542</span>     <span class="k">if</span> <span class="n">chunk</span><span class="p">:</span>  <span class="c1"># filter out keep-alive new chunks</span>
<span class="g g-Whitespace">    </span><span class="mi">543</span>         <span class="n">progress</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">))</span>
<span class="ne">--&gt; </span><span class="mi">544</span>         <span class="n">temp_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">546</span> <span class="k">if</span> <span class="n">expected_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">expected_size</span> <span class="o">!=</span> <span class="n">temp_file</span><span class="o">.</span><span class="n">tell</span><span class="p">():</span>
<span class="g g-Whitespace">    </span><span class="mi">547</span>     <span class="k">raise</span> <span class="ne">EnvironmentError</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">548</span>         <span class="sa">f</span><span class="s2">&quot;Consistency check failed: file should be of size </span><span class="si">{</span><span class="n">expected_size</span><span class="si">}</span><span class="s2"> but has size&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">549</span>         <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">temp_file</span><span class="o">.</span><span class="n">tell</span><span class="p">()</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">displayed_name</span><span class="si">}</span><span class="s2">).</span><span class="se">\n</span><span class="s2">We are sorry for the inconvenience. Please retry download and&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">550</span>         <span class="s2">&quot; pass `force_download=True, resume_download=False` as argument.</span><span class="se">\n</span><span class="s2">If the issue persists, please let us&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">551</span>         <span class="s2">&quot; know by opening an issue on https://github.com/huggingface/huggingface_hub.&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">552</span>     <span class="p">)</span>

<span class="nn">File ~/anaconda3/lib/python3.11/tempfile.py:483,</span> in <span class="ni">_TemporaryFileWrapper.__getattr__.&lt;locals&gt;.func_wrapper</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">481</span> <span class="nd">@_functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">482</span> <span class="k">def</span> <span class="nf">func_wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">483</span>     <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</section>
<section id="question-answering">
<h2>question-answering<a class="headerlink" href="#question-answering" title="Permalink to this heading">#</a></h2>
<p>Takes an input question and context and provides an answer</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># calling the question-answer pipeline</span>
<span class="c1"># passing a question and context into the pipeline</span>
<span class="c1"># the function will look into the context to get the answer</span>

<span class="n">question_answer</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;question-answering&#39;</span><span class="p">)</span>
<span class="n">question_answer</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="s1">&#39;Was the writer of Frankenstien a man or a woman?&#39;</span><span class="p">,</span> 
                <span class="n">context</span><span class="o">=</span><span class="s1">&#39;&#39;&#39;Frankenstien is a book written by Mary Shelley who is </span>
<span class="s1">                a woman&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).
Using a pipeline without specifying a model name and revision in production is not recommended.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;score&#39;: 0.6520994901657104, &#39;start&#39;: 71, &#39;end&#39;: 78, &#39;answer&#39;: &#39;a woman&#39;}
</pre></div>
</div>
</div>
</div>
</section>
<section id="ner-named-entity-recognition">
<h2>ner (named entity recognition)<a class="headerlink" href="#ner-named-entity-recognition" title="Permalink to this heading">#</a></h2>
<p>Named entity recognition (NER) is a task where the model has to find which parts of the input text correspond to entities such as persons, locations, or organizations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ner</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;ner&quot;</span><span class="p">,</span> <span class="n">grouped_entities</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ner</span><span class="p">(</span><span class="s2">&quot;My name is Filipa Calado and I work at City College in Manhattan.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).
Using a pipeline without specifying a model name and revision in production is not recommended.
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "e6d2e774a63c459f9f53b35227bac4dc"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "22a0dceb96994afabd0c44c4968ba1cd"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "a6e3c1f389824e41bb0063e3c6f0015a"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "4133165a1f9d47f0b2d146cabe9ee98e"}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.9/dist-packages/transformers/pipelines/token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=&quot;simple&quot;` instead.
  warnings.warn(
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[{&#39;entity_group&#39;: &#39;PER&#39;,
  &#39;score&#39;: 0.9985998,
  &#39;word&#39;: &#39;Filipa Calado&#39;,
  &#39;start&#39;: 11,
  &#39;end&#39;: 24},
 {&#39;entity_group&#39;: &#39;ORG&#39;,
  &#39;score&#39;: 0.9940423,
  &#39;word&#39;: &#39;City College&#39;,
  &#39;start&#39;: 39,
  &#39;end&#39;: 51},
 {&#39;entity_group&#39;: &#39;LOC&#39;,
  &#39;score&#39;: 0.9883624,
  &#39;word&#39;: &#39;Manhattan&#39;,
  &#39;start&#39;: 55,
  &#39;end&#39;: 64}]
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="nltk-gender.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">NLTK: text analysis</p>
      </div>
    </a>
    <a class="right-next"
       href="generating_language.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">transformers: generating language</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-generation">text generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fill-mask">fill mask</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summarization">summarization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#question-answering">question-answering</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ner-named-entity-recognition">ner (named entity recognition)</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Filipa Calado
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>